{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "398b1bab-f9a3-4866-b14b-5e768aee19c0",
   "metadata": {},
   "source": [
    "# Neural Nets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b457f137-067f-455e-b4b4-41107c0a16c6",
   "metadata": {},
   "source": [
    "Notebook by MacKenzye Leroy exploring basic neural nets with our capstone data <br>\n",
    "1/26/21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16c58470-d1c8-4927-8ed4-ef5b9642b8b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow_probability as tfp\n",
    "from platform import python_version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ceff3583-b17b-4a20-831a-794e9e35a568",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c458bbfe-f258-40ce-a3bb-dca2715339e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.8.8'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "python_version() #I was using 3.8.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e79df0bd-5d91-4db6-8329-50dad96cabe7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.7.0'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__ #I was using 2.7.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b29b806c-3212-4521-a47a-adbf3effe1e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ca47439-a64f-4430-9436-b6c3687e38c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/Users/mackenzyeleroy/Documents/Capstone/Getting_data_for_FSL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d513bdec-4d0b-4401-8e27-a9566fc5b09a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function for getting precitions, true positive, true negative,false posisitve, false negative, accuracy, recall and precsion\n",
    "def getTestResults(fitted_model, test_df, test_labels):\n",
    "    result = pd.DataFrame(fitted_model.predict(test_df), test_labels).reset_index()\n",
    "\n",
    "    result['prediction'] = (result[0] > .5).astype(int)\n",
    "    result = result.rename(columns = {0: 'score', 'index': 'outcome'})\n",
    "    result['correct'] = result['outcome'] == result['prediction']\n",
    "    result['true_positive'] = result[result['prediction'] == 1]['prediction'] == result[result['prediction'] == 1]['correct']\n",
    "    result['false_positive'] = result[result['prediction'] == 1]['prediction'] != result[result['prediction'] == 1]['correct']\n",
    "    result['true_negative'] = result[result['prediction'] == 0]['prediction'] == 1- result[result['prediction'] == 0]['correct']\n",
    "    result['false_negative'] = result[result['prediction'] == 0]['prediction'] == result[result['prediction'] == 0]['correct']\n",
    "\n",
    "    result = result.fillna(False)\n",
    "\n",
    "    #TP, FP, FN, TN\n",
    "    true_postive= round(result.true_positive.sum(), 4)\n",
    "    false_postive = round(result.false_positive.sum(), 4)\n",
    "    true_negative = round(result.true_negative.sum(), 4)\n",
    "    false_negative = round(result.false_negative.sum(), 4)\n",
    "\n",
    "    #Accuracy/Preciosn/Recall\n",
    "    accuracy = round(result.correct.sum()/len(result), 4)\n",
    "    precision = round(true_postive/(true_postive + false_postive), 4)\n",
    "    recall = round(true_postive/(true_postive + false_negative), 4)\n",
    "    \n",
    "    print(f\"\"\"Accuracy: {accuracy} \\n\n",
    "            True Positive: {true_postive} False Positive: {false_postive} \\n\n",
    "            False Negative: {false_negative} True negative: {true_negative} \\n\n",
    "            Precision {precision} recall {recall}\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d00aae6d-87ea-42fb-b9e0-78fc11b9fb94",
   "metadata": {},
   "source": [
    "First, looking at a 2-D Neural Net (aka one parameter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2061ab24-a298-47a1-819f-aecb2ca45693",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define Model\n",
    "\n",
    "BATCH_SIZE = 5\n",
    "def get_basic_model():\n",
    "    model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape = (199, )),\n",
    "    #tf.keras.layers.Dense(128, activation='sigmoid'),\n",
    "    tf.keras.layers.Dense(56, activation='sigmoid'),\n",
    "    tf.keras.layers.Dense(28, activation='sigmoid'),\n",
    "    tf.keras.layers.Dense(1)\n",
    "  ])\n",
    "\n",
    "    model.compile(optimizer='adam',\n",
    "                loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bd37879-d5c1-4c39-b313-21948db7f53f",
   "metadata": {},
   "source": [
    "Notes about model:\n",
    "* First layer flattens data into 1-D vector\n",
    "* Second layer (1st hidden) is comprised of 56 nodes and the activation function is a sigmoid\n",
    "* Third layer (2nd hidden) is comprised of 28 nodes and the activation function is a sigmoid\n",
    "* Final ouptput layer is one node\n",
    "\n",
    "\n",
    "While the sigmoid function is less popular today (was very popular in 90's) it worked better for me. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1ed8209b-81be-4c95-a822-65f4b1abf35d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Initalize dataframe to save results\n",
    "result = pd.DataFrame(columns = ['Parameter', 'Training Loss', 'Training Accuracy'])\n",
    "\n",
    "#function for readinf in files and getting into manner that's ready for model defined above\n",
    "def importAndPrepFiles(parameter_number):   \n",
    "    #file names\n",
    "    test_file = f\"PARM{parameter_number}_TEST.tsv\"\n",
    "    train_file = f\"PARM{parameter_number}_TRAIN.tsv\"\n",
    "    \n",
    "    #read in as a pandas dataframe\n",
    "    test_dataset = pd.read_csv(test_file, sep='\\t', header = None)\n",
    "    train_dataset = pd.read_csv(train_file, sep='\\t', header = None)\n",
    "\n",
    "    #change names to strings because tensorflow doesn't like woring with unnamed indexed columns\n",
    "    column_names = ['f' + str(x) for x in train_dataset.columns]\n",
    "    column_names[0] = 'outcome'\n",
    "\n",
    "    #change column names\n",
    "    train_dataset.columns = column_names\n",
    "    test_dataset.columns = column_names\n",
    "\n",
    "    #change -1 (fault) to 0-Tensorflow's Binary Corss Entropy Function needs 0/1\n",
    "    train_dataset['outcome'] = train_dataset['outcome'].replace(-1, 0)\n",
    "    test_dataset['outcome'] = test_dataset['outcome'].replace(-1, 0)\n",
    "\n",
    "    #pop labels off and save separetely\n",
    "    target_train = train_dataset.pop('outcome')\n",
    "    target_test = test_dataset.pop('outcome')\n",
    "    \n",
    "    #convert datasets and labels to tensors\n",
    "    train_dataset = tf.convert_to_tensor(train_dataset)\n",
    "    target_train = tf.convert_to_tensor(target_train)\n",
    "    test_dataset = tf.convert_to_tensor(test_dataset)\n",
    "    target_test = tf.convert_to_tensor(target_test)\n",
    "    \n",
    "    #return list\n",
    "    return [train_dataset, target_train, test_dataset, target_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8c41dc95-b08f-45f7-a52e-68403b4625ab",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter: 0 Training Loss: 0.5639533400535583 Training Accuracy: 0.6865671873092651\n",
      "Parameter: 1 Training Loss: 0.6904732584953308 Training Accuracy: 0.46268656849861145\n",
      "Parameter: 2 Training Loss: 0.5519682168960571 Training Accuracy: 0.7164179086685181\n",
      "Parameter: 3 Training Loss: 0.23164735734462738 Training Accuracy: 1.0\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7fdd83192670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Parameter: 4 Training Loss: 0.5672956705093384 Training Accuracy: 0.7164179086685181\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7fdd8253d550> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Parameter: 5 Training Loss: 0.24158737063407898 Training Accuracy: 1.0\n",
      "Parameter: 6 Training Loss: 0.5977708101272583 Training Accuracy: 0.7164179086685181\n",
      "Parameter: 7 Training Loss: 0.32627204060554504 Training Accuracy: 0.89552241563797\n",
      "Parameter: 8 Training Loss: 0.5583853721618652 Training Accuracy: 0.46268656849861145\n",
      "Parameter: 9 Training Loss: 0.5682279467582703 Training Accuracy: 0.46268656849861145\n",
      "Parameter: 10 Training Loss: 0.5658130645751953 Training Accuracy: 0.46268656849861145\n",
      "Parameter: 11 Training Loss: 0.5834546089172363 Training Accuracy: 0.46268656849861145\n",
      "Parameter: 12 Training Loss: 0.6829382181167603 Training Accuracy: 0.46268656849861145\n",
      "Parameter: 13 Training Loss: 0.6904374361038208 Training Accuracy: 0.46268656849861145\n",
      "Parameter: 14 Training Loss: 0.5519866347312927 Training Accuracy: 0.7313432693481445\n",
      "Parameter: 15 Training Loss: 0.5815169811248779 Training Accuracy: 0.611940324306488\n",
      "Parameter: 16 Training Loss: 0.580744743347168 Training Accuracy: 0.6865671873092651\n",
      "Parameter: 17 Training Loss: 0.544951856136322 Training Accuracy: 0.746268630027771\n",
      "Parameter: 18 Training Loss: 0.6652350425720215 Training Accuracy: 0.5820895433425903\n",
      "Parameter: 19 Training Loss: 0.5731330513954163 Training Accuracy: 0.7313432693481445\n",
      "Parameter: 20 Training Loss: 0.6178995966911316 Training Accuracy: 0.5970149040222168\n",
      "Parameter: 21 Training Loss: 0.5468568801879883 Training Accuracy: 0.611940324306488\n",
      "Parameter: 22 Training Loss: 0.6471273899078369 Training Accuracy: 0.6268656849861145\n",
      "Parameter: 23 Training Loss: 0.5770356059074402 Training Accuracy: 0.7313432693481445\n",
      "Parameter: 24 Training Loss: 0.6529910564422607 Training Accuracy: 0.46268656849861145\n",
      "Parameter: 25 Training Loss: 0.5359839200973511 Training Accuracy: 0.746268630027771\n",
      "Parameter: 26 Training Loss: 0.6730551719665527 Training Accuracy: 0.447761207818985\n",
      "Parameter: 27 Training Loss: 0.6722841262817383 Training Accuracy: 0.46268656849861145\n",
      "Parameter: 28 Training Loss: 0.5600358247756958 Training Accuracy: 0.7313432693481445\n",
      "Parameter: 29 Training Loss: 0.5469202995300293 Training Accuracy: 0.7313432693481445\n",
      "Parameter: 30 Training Loss: 0.6292597651481628 Training Accuracy: 0.46268656849861145\n",
      "Parameter: 31 Training Loss: 0.6034976243972778 Training Accuracy: 0.7313432693481445\n"
     ]
    }
   ],
   "source": [
    "#the following code reads in each parameter dataframe, fits a neural net with the data and return the accuracy and loss (on the training set)\n",
    "#Note: TensorFlow doesn't like me running model.fit in a for loop, so a warning may be thrown\n",
    "\n",
    "for x in range(32):\n",
    "    \n",
    "    #import/prep files\n",
    "    tensorList = importAndPrepFiles(x)\n",
    "    \n",
    "    train_dataset = tensorList[0]\n",
    "    target_train = tensorList[1]\n",
    "    #initiaite model\n",
    "    model = get_basic_model()\n",
    "\n",
    "    model.fit(train_dataset, target_train, epochs=50, verbose = 0)\n",
    "    train_loss, train_acc = model.evaluate(train_dataset, target_train, verbose = 0)\n",
    "    result.loc[x] = [x, train_loss, train_acc]\n",
    "    print(f\"Parameter: {x} Training Loss: {train_loss} Training Accuracy: {train_acc}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "88fb365f-8cf2-41b8-b27a-130af6fda360",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check for lowest loss\n",
    "result['Training Loss'].argmin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4d33d824-3d27-48fa-bb75-865e72365abd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check for highest accuracy\n",
    "result['Training Accuracy'].argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ae14141d-1750-4119-aacd-cf3760e59b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parameters 3 and 5 look good so let's check those indvidually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "92d46215-d081-46c3-9204-4f3a9ca706cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import and prep files\n",
    "parameter3_tensors = importAndPrepFiles(3)\n",
    "parameter5_tensors = importAndPrepFiles(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aded1669-7b15-4820-8742-2fe6504116f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 - 0s - loss: 0.2062 - accuracy: 1.0000 - 102ms/epoch - 34ms/step\n"
     ]
    }
   ],
   "source": [
    "#establish training and test sets for parameter 3\n",
    "train_dataset_param3 = parameter3_tensors[0]\n",
    "target_train_param3 = parameter3_tensors[1]\n",
    "test_dataset_param3 = parameter3_tensors[2]\n",
    "target_test_param3 = parameter3_tensors[3]\n",
    "\n",
    "model = get_basic_model()\n",
    "\n",
    "model.fit(train_dataset_param3, target_train_param3, epochs=50, verbose = 0)\n",
    "#check training accuracy/loss\n",
    "train_loss, train_acc = model.evaluate(train_dataset_param3, target_train_param3, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d767b416-7dc4-45b4-9e29-80cbf54063ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check against test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "71edb5b0-8852-459e-89ab-68ee8b9c3767",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 - 0s - loss: 0.5961 - accuracy: 0.6364 - 19ms/epoch - 10ms/step\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(test_dataset_param3, target_test_param3, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e9a5c2d6-fef3-4b49-ac4f-77032b7c7986",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6364 \n",
      "\n",
      "            True Positive: 4 False Positive: 2 \n",
      "\n",
      "            False Negative: 10 True negative: 17 \n",
      "\n",
      "            Precision 0.6667 recall 0.2857\n"
     ]
    }
   ],
   "source": [
    "getTestResults(model, test_dataset_param3,target_test_param3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "64c225e4-a65c-4390-9b1c-c3237f0ba992",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Repeat for parameter 5:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a5be09e9-17a0-4fdd-9456-48776e3da9de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 - 0s - loss: 0.1491 - accuracy: 1.0000 - 101ms/epoch - 34ms/step\n"
     ]
    }
   ],
   "source": [
    "#establish training and test sets for parameter 3\n",
    "train_dataset_param5 = parameter5_tensors[0]\n",
    "target_train_param5 = parameter5_tensors[1]\n",
    "test_dataset_param5 = parameter5_tensors[2]\n",
    "target_test_param5 = parameter5_tensors[3]\n",
    "\n",
    "model = get_basic_model()\n",
    "\n",
    "model.fit(train_dataset_param5, target_train_param5, epochs=50, verbose = 0)\n",
    "#check training accuracy/loss\n",
    "train_loss, train_acc = model.evaluate(train_dataset_param5, target_train_param5, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "621ca3cc-980c-4619-963b-d9eda12f244b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check against test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f7025ca5-2ee3-4966-9cd6-45cf03714141",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 - 0s - loss: 0.6839 - accuracy: 0.6364 - 18ms/epoch - 9ms/step\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(test_dataset_param3, target_test_param3, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e27caa1f-9b64-4771-8aeb-5f0afac54929",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c8075705-597e-4d0d-9a17-d381378f1ded",
   "metadata": {},
   "source": [
    "## 3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3860ca03-2f03-417c-a5cd-de6c6d49fd21",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load in each csv as dataframe and save it to list. \n",
    "\n",
    "training_df = []\n",
    "test_df = []\n",
    "for x in range(32):\n",
    "    \n",
    "    #file names\n",
    "    test_file = f\"PARM{x}_TEST.tsv\"\n",
    "    train_file = f\"PARM{x}_TRAIN.tsv\"\n",
    "    \n",
    "    #read in as dataframe\n",
    "    test_dataset = pd.read_csv(test_file, sep='\\t', header = None)\n",
    "    train_dataset = pd.read_csv(train_file, sep='\\t', header = None)\n",
    "    \n",
    "    #change names to strings because tensorflow doesn't like woring with unnamed indexed columns\n",
    "    column_names = ['f' + str(x) for x in train_dataset.columns]\n",
    "    column_names[0] = 'outcome'\n",
    "   \n",
    "    #change column names\n",
    "    train_dataset.columns = column_names\n",
    "    test_dataset.columns = column_names\n",
    "    \n",
    "    #change -1 (fault) to 0-Tensorflow's Binary Corss Entropy Function needs 0/1\n",
    "    train_dataset['outcome'] = train_dataset['outcome'].replace(-1, 0)\n",
    "    test_dataset['outcome'] = test_dataset['outcome'].replace(-1, 0)\n",
    "    \n",
    "    #pop labels off and save separetely\n",
    "    target_train = train_dataset.pop('outcome')\n",
    "    target_test = test_dataset.pop('outcome')\n",
    "    \n",
    "    #append to list\n",
    "    training_df.append(train_dataset)\n",
    "    test_df.append(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0c9f1c84-f74b-4e1c-95b3-7c11b07a6f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert lists of dataframes to 3d array\n",
    "training_3d = np.array(training_df)\n",
    "test_3d = np.array(test_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8cf7e2b4-a083-4bb7-8abf-fa18931e6a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "#swap axes-need 67 (number of observations) in x position\n",
    "training_3d = np.swapaxes(training_3d,0,1)\n",
    "test_3d = np.swapaxes(test_3d,0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3cad690c-6185-4865-bc0e-13d12f309af9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([67, 32, 199])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#convert to tensor and check shape\n",
    "training_3d = tf.convert_to_tensor(training_3d)\n",
    "training_3d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1fb1e0f8-1a5c-42b5-9e3d-f1f319155fa0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([33, 32, 199])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#convert to tensor and check shape\n",
    "test_3d = tf.convert_to_tensor(test_3d)\n",
    "test_3d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "405241fa-9460-4b08-ac8e-5adf016feb5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define Model of 3d Input\n",
    "\n",
    "BATCH_SIZE = 5\n",
    "def get_basic_model_3d():\n",
    "    model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape = (32, 199, )),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(56, activation='relu'),\n",
    "    tf.keras.layers.Dense(28, activation='relu'),\n",
    "    tf.keras.layers.Dense(1)\n",
    "  ])\n",
    "\n",
    "    model.compile(optimizer='adam',\n",
    "                loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                metrics=['accuracy',])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8247a882-a927-4203-8c44-47ee377dda8a",
   "metadata": {},
   "source": [
    "Notes about Model:\n",
    "* First layer is a flatten layer again, but this time flattens across an extra dimension (resulting vector is 400K+ elements long\n",
    "* Second layer is comprised of 128 nodes with a relu activation function\n",
    "* Final layers are the same as 2D model above as far as nodes go, but activition function is relu now\n",
    "\n",
    "For the 3d model, relu worked better than sigmoid this time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "01be67b9-a779-439d-8543-287ca6a6c783",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Really good Result Model: (with 200 epochs)\n",
    "#def get_basic_model_3d():\n",
    "#    model = tf.keras.Sequential([\n",
    "#    tf.keras.layers.Flatten(input_shape = (32, 199, )),\n",
    "#    tf.keras.layers.Dense(128, activation='relu'),\n",
    "#    tf.keras.layers.Dense(56, activation='relu'),\n",
    "#    tf.keras.layers.Dense(28, activation='relu'),\n",
    "#    tf.keras.layers.Dense(1)\n",
    "#  ])\n",
    "\n",
    "#    model.compile(optimizer='adam',\n",
    "#                loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "#                metrics=['accuracy',])\n",
    "#    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0146a30b-f17c-4ece-88c1-27214e843f36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3366d320-57c1-4538-97cb-0bb9437a2505",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 - 0s - loss: 7.4548e-10 - accuracy: 1.0000 - 112ms/epoch - 37ms/step\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 20\n",
    "\n",
    "#initiate model\n",
    "model = get_basic_model_3d()\n",
    "\n",
    "#fit model\n",
    "model.fit(training_3d, target_train, epochs=200, verbose = 0, batch_size = BATCH_SIZE)\n",
    "\n",
    "#check training loss and accuracy\n",
    "train_loss, train_acc = model.evaluate(training_3d, target_train, verbose = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5747ffde-2bca-4211-b85c-7c5a0a70a0ff",
   "metadata": {},
   "source": [
    "#### Training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e58db5ea-76cf-427c-82aa-978fb4d9e89c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0 \n",
      "\n",
      "            True Positive: 36 False Positive: 0 \n",
      "\n",
      "            False Negative: 0 True negative: 31 \n",
      "\n",
      "            Precision 1.0 recall 1.0\n"
     ]
    }
   ],
   "source": [
    "#get full results for training\n",
    "getTestResults(model, training_3d, target_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b68113d-0fc4-4401-9041-ccc3ea7e23b7",
   "metadata": {},
   "source": [
    "#### Test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "968ae457-3574-4305-874b-6b058d11cce0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 - 0s - loss: 181.5024 - accuracy: 0.5758 - 19ms/epoch - 10ms/step\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(test_3d, target_test, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "996a3298-809b-479d-bc5c-59fdfb21120e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5758 \n",
      "\n",
      "            True Positive: 6 False Positive: 6 \n",
      "\n",
      "            False Negative: 8 True negative: 13 \n",
      "\n",
      "            Precision 0.5 recall 0.4286\n"
     ]
    }
   ],
   "source": [
    "getTestResults(model, test_3d, target_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844d0a1d-91b7-4514-a9fb-69075ee43c6d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
