{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "398b1bab-f9a3-4866-b14b-5e768aee19c0",
      "metadata": {
        "id": "398b1bab-f9a3-4866-b14b-5e768aee19c0"
      },
      "source": [
        "## Neural Nets"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install pyts"
      ],
      "metadata": {
        "id": "-2hINtdfaNU7"
      },
      "id": "-2hINtdfaNU7",
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "b457f137-067f-455e-b4b4-41107c0a16c6",
      "metadata": {
        "id": "b457f137-067f-455e-b4b4-41107c0a16c6"
      },
      "source": [
        "Import"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "16c58470-d1c8-4927-8ed4-ef5b9642b8b1",
      "metadata": {
        "id": "16c58470-d1c8-4927-8ed4-ef5b9642b8b1"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "#import tensorflow_datasets as tfds\n",
        "# import tensorflow_probability as tfp"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## SFA imports\n",
        "from pyts.bag_of_words import BagOfWords\n",
        "from pyts.transformation import BOSS"
      ],
      "metadata": {
        "id": "PnHgmfcMaJju"
      },
      "id": "PnHgmfcMaJju",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "0ca47439-a64f-4430-9436-b6c3687e38c7",
      "metadata": {
        "id": "0ca47439-a64f-4430-9436-b6c3687e38c7"
      },
      "outputs": [],
      "source": [
        "# setting directory\n",
        "# have this set to where ever the Getting_data_for_FSL folder Colin made is saved\n",
        "os.chdir('/content/Getting_data_for_FSL')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Looking at SFA data (just parm 17)"
      ],
      "metadata": {
        "id": "EhN6UqIVkOTq"
      },
      "id": "EhN6UqIVkOTq"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pPa6hR5kkOTr"
      },
      "outputs": [],
      "source": [
        "test_file = \"PARM17_TEST.tsv\"\n",
        "train_file = \"PARM17_TRAIN.tsv\""
      ],
      "id": "pPa6hR5kkOTr"
    },
    {
      "cell_type": "code",
      "source": [
        "## Getting Test and Training X and Y ###\n",
        "test_dataset = pd.read_csv(test_file, sep='\\t', header = None)\n",
        "train_dataset = pd.read_csv(train_file, sep='\\t', header = None)\n",
        "\n",
        "column_names = ['f' + str(x) for x in train_dataset.columns]\n",
        "column_names[0] = 'outcome'\n",
        "#column_names \n",
        "\n",
        "train_dataset.columns = column_names\n",
        "test_dataset.columns = column_names\n",
        "\n",
        "\n",
        "train_dataset['outcome'] = train_dataset['outcome'].replace(-1, 0)\n",
        "test_dataset['outcome'] = test_dataset['outcome'].replace(-1, 0)\n",
        "\n",
        "\n",
        "target_train = train_dataset.pop('outcome')\n",
        "target_test = test_dataset.pop('outcome')"
      ],
      "metadata": {
        "id": "1aoRqpRekOTr"
      },
      "execution_count": null,
      "outputs": [],
      "id": "1aoRqpRekOTr"
    },
    {
      "cell_type": "code",
      "source": [
        "## SFA feature engineering ##\n",
        "\n",
        "## Setting Parameters\n",
        "window_size = 10 # how long are the equally split indexes\n",
        "word_size = 3 # how long is each possible word\n",
        "n_bins=2 # number of letters in local universe of the alphabet\n",
        "\n",
        "## BOSS transformation\n",
        "\n",
        "boss = BOSS(word_size=word_size, n_bins=n_bins, window_size=window_size, sparse=False, numerosity_reduction=False)   ## Note, you would typically have numerosity_reduction set to True\n",
        "\n",
        "train_boss = boss.fit_transform(train_dataset)\n",
        "test_boss = boss.fit_transform(test_dataset)\n",
        "\n",
        "## vocabulary input (for NN)\n",
        "\n",
        "vocab_total = train_boss.shape[1]"
      ],
      "metadata": {
        "id": "tSHR3kU6kOTs"
      },
      "execution_count": null,
      "outputs": [],
      "id": "tSHR3kU6kOTs"
    },
    {
      "cell_type": "code",
      "source": [
        "## making new model (different input_shape now based on SFA)\n",
        "\n",
        "BATCH_SIZE = 5.   \n",
        "def get_basic_model_SFA():\n",
        "    model = tf.keras.Sequential([\n",
        "    # tf.keras.layers.Flatten(input_shape = (32, 199, )),\n",
        "    tf.keras.layers.Flatten(input_shape = (vocab_total, )),\n",
        "    #tf.keras.layers.Dense(128, activation='sigmoid'),\n",
        "    tf.keras.layers.Dense(56, activation='sigmoid'),\n",
        "    tf.keras.layers.Dense(28, activation='sigmoid'),   ##### can change n(numbers and activation)\n",
        "    tf.keras.layers.Dense(1)\n",
        "  ])\n",
        "\n",
        "    model.compile(optimizer='adam',\n",
        "                loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "                metrics=['accuracy'])\n",
        "    return model"
      ],
      "metadata": {
        "id": "PzCF14QRkOTs"
      },
      "execution_count": null,
      "outputs": [],
      "id": "PzCF14QRkOTs"
    },
    {
      "cell_type": "code",
      "source": [
        "## some final formating and running model\n",
        "\n",
        "train_dataset_BOSS = tf.convert_to_tensor(train_boss)\n",
        "target_train = tf.convert_to_tensor(target_train)\n",
        "\n",
        "test_dataset_BOSS = tf.convert_to_tensor(test_boss)\n",
        "target_test = tf.convert_to_tensor(target_test)\n",
        "\n",
        "#Data already normalized (Data is Not normalized, potential down the line issue)\n",
        "\n",
        "model = get_basic_model_SFA()\n",
        "\n",
        "model.fit(train_dataset_BOSS, target_train, epochs=50, verbose = 0)\n",
        "test_loss, test_acc = model.evaluate(train_dataset_BOSS, target_train, verbose = 2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e8640b4-217a-4f59-8be2-0c22d9ced532",
        "id": "8nSkww22kOTs"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3/3 - 0s - loss: 0.5743 - accuracy: 0.7164 - 122ms/epoch - 41ms/step\n"
          ]
        }
      ],
      "id": "8nSkww22kOTs"
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_acc = model.evaluate(test_dataset_BOSS, target_test, verbose = 2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "99985c2a-caa5-4841-d153-a43298c96bf9",
        "id": "8FrvBVlWkOTs"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 - 0s - loss: 0.5828 - accuracy: 0.7576 - 19ms/epoch - 10ms/step\n"
          ]
        }
      ],
      "id": "8FrvBVlWkOTs"
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "a6QZKxxDkOTt"
      },
      "execution_count": null,
      "outputs": [],
      "id": "a6QZKxxDkOTt"
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "5iSGBs5DkGSa"
      },
      "id": "5iSGBs5DkGSa",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "v-yl5-DTkGUj"
      },
      "id": "v-yl5-DTkGUj",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "iiUtbSb9kGWl"
      },
      "id": "iiUtbSb9kGWl",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Older Code (will be modifed to run SFA on all parameters)"
      ],
      "metadata": {
        "id": "aapOUcDDkZ5b"
      },
      "id": "aapOUcDDkZ5b"
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "u9W60DeZkGYu"
      },
      "id": "u9W60DeZkGYu",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "2061ab24-a298-47a1-819f-aecb2ca45693",
      "metadata": {
        "id": "2061ab24-a298-47a1-819f-aecb2ca45693"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "OIJOc5hjX1Uj"
      },
      "id": "OIJOc5hjX1Uj"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "0b40597a-0f22-488f-88eb-87c914288d2a",
      "metadata": {
        "id": "0b40597a-0f22-488f-88eb-87c914288d2a"
      },
      "outputs": [],
      "source": [
        "training_df = []\n",
        "test_df = []\n",
        "for x in range(32):\n",
        "    \n",
        "    test_file = f\"PARM{x}_TEST.tsv\"\n",
        "    train_file = f\"PARM{x}_TRAIN.tsv\"\n",
        "    \n",
        "    test_dataset = pd.read_csv(test_file, sep='\\t', header = None)\n",
        "    train_dataset = pd.read_csv(train_file, sep='\\t', header = None)\n",
        "    \n",
        "    column_names = ['f' + str(x) for x in train_dataset.columns]\n",
        "    column_names[0] = 'outcome'\n",
        "   \n",
        "\n",
        "    train_dataset.columns = column_names\n",
        "    test_dataset.columns = column_names\n",
        "    \n",
        "    train_dataset['outcome'] = train_dataset['outcome'].replace(-1, 0)\n",
        "    test_dataset['outcome'] = test_dataset['outcome'].replace(-1, 0)\n",
        "    \n",
        "    target_train = train_dataset.pop('outcome')\n",
        "    target_test = test_dataset.pop('outcome')\n",
        "    \n",
        "    training_df.append(train_dataset)\n",
        "    test_df.append(test_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "cd8cf6c0-6cea-471c-bdf9-391c4dad43d5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cd8cf6c0-6cea-471c-bdf9-391c4dad43d5",
        "outputId": "a78b6c54-7127-4b0b-dc68-5f61ade2a68f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(32, 67, 199)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "training_3d = np.array(training_df)\n",
        "training_3d.shape\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "22e4c6d9-c038-4728-b566-f4006feb25ee",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "22e4c6d9-c038-4728-b566-f4006feb25ee",
        "outputId": "c2829654-71ff-4799-bd84-50647433b82b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(32, 199, 67)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "training_3d = np.swapaxes(training_3d,1,2)\n",
        "training_3d.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dbadbe95-d628-4c4b-ad79-9b8ad71a5fe2",
      "metadata": {
        "id": "dbadbe95-d628-4c4b-ad79-9b8ad71a5fe2"
      },
      "source": [
        "training_3d = np.array(training_df)\n",
        "test_3d = test_df\n",
        "target_train_3d = []\n",
        "for x in range(32):\n",
        "    pop = training_3d[x]['outcome']\n",
        "    target_train_3d.append(pop)\n",
        "    \n",
        "\n",
        "target_train_3d\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "a6e46968-f269-4032-8050-b926816d155e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a6e46968-f269-4032-8050-b926816d155e",
        "outputId": "a66d3da8-bff6-4a2e-d3e5-a154b86692a3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f692ee98690>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "model = get_basic_model()\n",
        "\n",
        "model.fit(train_dataset, target_train, epochs=40, verbose = 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "dad91f7d-c1f9-4b12-b60a-0990702c0348",
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dad91f7d-c1f9-4b12-b60a-0990702c0348",
        "outputId": "e10e7033-5768-4103-d273-f2654381971d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameter: 0 Training Loss: 0.5622822642326355 Training Accuracy: 0.7164179086685181\n",
            "Parameter: 1 Training Loss: 0.69056236743927 Training Accuracy: 0.46268656849861145\n",
            "Parameter: 2 Training Loss: 0.5526850819587708 Training Accuracy: 0.7164179086685181\n",
            "Parameter: 3 Training Loss: 0.2233283519744873 Training Accuracy: 1.0\n",
            "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7f692e62e290> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "Parameter: 4 Training Loss: 0.5561310648918152 Training Accuracy: 0.7164179086685181\n",
            "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7f692760e560> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "Parameter: 5 Training Loss: 0.28016719222068787 Training Accuracy: 1.0\n",
            "Parameter: 6 Training Loss: 0.5557876229286194 Training Accuracy: 0.7313432693481445\n",
            "Parameter: 7 Training Loss: 0.46105676889419556 Training Accuracy: 0.9552238583564758\n",
            "Parameter: 8 Training Loss: 0.5602486729621887 Training Accuracy: 0.7164179086685181\n",
            "Parameter: 9 Training Loss: 0.579302966594696 Training Accuracy: 0.7164179086685181\n",
            "Parameter: 10 Training Loss: 0.5798256993293762 Training Accuracy: 0.46268656849861145\n",
            "Parameter: 11 Training Loss: 0.577571451663971 Training Accuracy: 0.611940324306488\n",
            "Parameter: 12 Training Loss: 0.6799724102020264 Training Accuracy: 0.46268656849861145\n",
            "Parameter: 13 Training Loss: 0.6906750202178955 Training Accuracy: 0.46268656849861145\n",
            "Parameter: 14 Training Loss: 0.5487578511238098 Training Accuracy: 0.7313432693481445\n",
            "Parameter: 15 Training Loss: 0.5865713357925415 Training Accuracy: 0.7313432693481445\n",
            "Parameter: 16 Training Loss: 0.6111871004104614 Training Accuracy: 0.641791045665741\n",
            "Parameter: 17 Training Loss: 0.5464616417884827 Training Accuracy: 0.746268630027771\n",
            "Parameter: 18 Training Loss: 0.6566960215568542 Training Accuracy: 0.5970149040222168\n",
            "Parameter: 19 Training Loss: 0.5990250706672668 Training Accuracy: 0.5373134613037109\n",
            "Parameter: 20 Training Loss: 0.6206490993499756 Training Accuracy: 0.6268656849861145\n",
            "Parameter: 21 Training Loss: 0.5427507758140564 Training Accuracy: 0.7313432693481445\n",
            "Parameter: 22 Training Loss: 0.6565464735031128 Training Accuracy: 0.6567164063453674\n",
            "Parameter: 23 Training Loss: 0.5966989994049072 Training Accuracy: 0.46268656849861145\n",
            "Parameter: 24 Training Loss: 0.6090035438537598 Training Accuracy: 0.641791045665741\n",
            "Parameter: 25 Training Loss: 0.5393630266189575 Training Accuracy: 0.746268630027771\n",
            "Parameter: 26 Training Loss: 0.6872480511665344 Training Accuracy: 0.5373134613037109\n",
            "Parameter: 27 Training Loss: 0.6702787280082703 Training Accuracy: 0.46268656849861145\n",
            "Parameter: 28 Training Loss: 0.5744743943214417 Training Accuracy: 0.46268656849861145\n",
            "Parameter: 29 Training Loss: 0.5606286525726318 Training Accuracy: 0.7313432693481445\n",
            "Parameter: 30 Training Loss: 0.642558217048645 Training Accuracy: 0.46268656849861145\n",
            "Parameter: 31 Training Loss: 0.6326997876167297 Training Accuracy: 0.46268656849861145\n"
          ]
        }
      ],
      "source": [
        "result = pd.DataFrame(columns = ['Parameter', 'Training Loss', 'Training Accuracy'])\n",
        "for x in range(32):\n",
        "    \n",
        "    test_file = f\"PARM{x}_TEST.tsv\"\n",
        "    train_file = f\"PARM{x}_TRAIN.tsv\"\n",
        "    #'15_TEST.tsv'\n",
        "    #'PARM15_TRAIN.tsv'\n",
        "    \n",
        "    test_dataset = pd.read_csv(test_file, sep='\\t', header = None)\n",
        "    train_dataset = pd.read_csv(train_file, sep='\\t', header = None)\n",
        "\n",
        "    column_names = ['f' + str(x) for x in train_dataset.columns]\n",
        "    column_names[0] = 'outcome'\n",
        "    #column_names \n",
        "\n",
        "    train_dataset.columns = column_names\n",
        "    test_dataset.columns = column_names\n",
        "\n",
        "\n",
        "    train_dataset['outcome'] = train_dataset['outcome'].replace(-1, 0)\n",
        "    test_dataset['outcome'] = test_dataset['outcome'].replace(-1, 0)\n",
        "\n",
        "\n",
        "    target_train = train_dataset.pop('outcome')\n",
        "    target_test = test_dataset.pop('outcome')\n",
        "\n",
        "    train_dataset = tf.convert_to_tensor(train_dataset)\n",
        "    target_train = tf.convert_to_tensor(target_train)\n",
        "\n",
        "    test_dataset = tf.convert_to_tensor(test_dataset)\n",
        "    target_test = tf.convert_to_tensor(target_test)\n",
        "\n",
        "    #Data already normalized\n",
        "\n",
        "    model = get_basic_model()\n",
        "\n",
        "    model.fit(train_dataset, target_train, epochs=40, verbose = 0)\n",
        "    train_loss, train_acc = model.evaluate(train_dataset, target_train, verbose = 0)\n",
        "    result.loc[x] = [x, train_loss, train_acc]\n",
        "    print(f\"Parameter: {x} Training Loss: {train_loss} Training Accuracy: {train_acc}\")\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "88fb365f-8cf2-41b8-b27a-130af6fda360",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "88fb365f-8cf2-41b8-b27a-130af6fda360",
        "outputId": "ccbda5a0-eef2-4516-be54-8979b779de6b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "result['Training Loss'].argmin()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "4d33d824-3d27-48fa-bb75-865e72365abd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4d33d824-3d27-48fa-bb75-865e72365abd",
        "outputId": "9a9f9f23-c77c-4be0-bde6-2de59e36fab1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "result['Training Accuracy'].argmax()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "fHvG1tHiYbKO"
      },
      "id": "fHvG1tHiYbKO",
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "u4RzvfT8YbMX"
      },
      "id": "u4RzvfT8YbMX",
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "eOhH5yMHYbOj"
      },
      "id": "eOhH5yMHYbOj",
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "vVh81ecWYbRG"
      },
      "id": "vVh81ecWYbRG",
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "1SIjoizsYbTU"
      },
      "id": "1SIjoizsYbTU",
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "981e8e53-2ccd-4e3d-bd1a-968d4051efb7",
      "metadata": {
        "id": "981e8e53-2ccd-4e3d-bd1a-968d4051efb7"
      },
      "source": [
        "Just looking at parameter 3:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "92d46215-d081-46c3-9204-4f3a9ca706cc",
      "metadata": {
        "id": "92d46215-d081-46c3-9204-4f3a9ca706cc"
      },
      "outputs": [],
      "source": [
        "test_file = \"PARM17_TEST.tsv\"\n",
        "train_file = \"PARM17_TRAIN.tsv\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "aded1669-7b15-4820-8742-2fe6504116f1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aded1669-7b15-4820-8742-2fe6504116f1",
        "outputId": "e1faa395-119c-4cec-d57a-6c46e8595f8f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3/3 - 0s - loss: 0.5405 - accuracy: 0.7313 - 131ms/epoch - 44ms/step\n"
          ]
        }
      ],
      "source": [
        "test_dataset = pd.read_csv(test_file, sep='\\t', header = None)\n",
        "train_dataset = pd.read_csv(train_file, sep='\\t', header = None)\n",
        "\n",
        "column_names = ['f' + str(x) for x in train_dataset.columns]\n",
        "column_names[0] = 'outcome'\n",
        "#column_names \n",
        "\n",
        "train_dataset.columns = column_names\n",
        "test_dataset.columns = column_names\n",
        "\n",
        "\n",
        "train_dataset['outcome'] = train_dataset['outcome'].replace(-1, 0)\n",
        "test_dataset['outcome'] = test_dataset['outcome'].replace(-1, 0)\n",
        "\n",
        "\n",
        "target_train = train_dataset.pop('outcome')\n",
        "target_test = test_dataset.pop('outcome')\n",
        "\n",
        "train_dataset = tf.convert_to_tensor(train_dataset)\n",
        "target_train = tf.convert_to_tensor(target_train)\n",
        "\n",
        "test_dataset = tf.convert_to_tensor(test_dataset)\n",
        "target_test = tf.convert_to_tensor(target_test)\n",
        "\n",
        "#Data already normalized\n",
        "\n",
        "model = get_basic_model()\n",
        "\n",
        "model.fit(train_dataset, target_train, epochs=50, verbose = 0)\n",
        "test_loss, test_acc = model.evaluate(train_dataset, target_train, verbose = 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "71edb5b0-8852-459e-89ab-68ee8b9c3767",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "71edb5b0-8852-459e-89ab-68ee8b9c3767",
        "outputId": "b8d36d38-b0e0-4646-cd4a-215217c3422f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 - 0s - loss: 0.4992 - accuracy: 0.7576 - 19ms/epoch - 9ms/step\n"
          ]
        }
      ],
      "source": [
        "test_loss, test_acc = model.evaluate(test_dataset, target_test, verbose = 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "64c225e4-a65c-4390-9b1c-c3237f0ba992",
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "64c225e4-a65c-4390-9b1c-c3237f0ba992",
        "outputId": "5baf36ec-5b5e-4bfb-c05b-2389ead92fe0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 6ms/step\n"
          ]
        }
      ],
      "source": [
        "pred = model.predict(test_dataset, verbose = True)\n",
        "yhat = []\n",
        "for x in range(32):\n",
        "    yhat.append(pred[x][0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "3ebc0b39-1937-43f3-b61e-58e0474d78b3",
      "metadata": {
        "id": "3ebc0b39-1937-43f3-b61e-58e0474d78b3"
      },
      "outputs": [],
      "source": [
        "yhat = (model.predict(test_dataset) > 0.5).astype(\"int32\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "6ea80f67-d630-4edc-b498-2fb473717e1e",
      "metadata": {
        "id": "6ea80f67-d630-4edc-b498-2fb473717e1e"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "e85ab699-46fe-463a-81d5-ac1e0ac911f5",
      "metadata": {
        "id": "e85ab699-46fe-463a-81d5-ac1e0ac911f5"
      },
      "outputs": [],
      "source": [
        "result = pd.DataFrame()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "03f953d0-d4ae-40f3-b8fd-283d3c132ed0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 346
        },
        "id": "03f953d0-d4ae-40f3-b8fd-283d3c132ed0",
        "outputId": "0db5a411-e344-434e-b38c-ddc58abd1d41"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "Exception",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-5e92a2c0ba26>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'yhat'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0myhat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'actual'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget_test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3042\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3043\u001b[0m             \u001b[0;31m# set column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3044\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3045\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3046\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_setitem_slice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_set_item\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3117\u001b[0m         \u001b[0mensure\u001b[0m \u001b[0mhomogeneity\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3118\u001b[0m         \"\"\"\n\u001b[0;32m-> 3119\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_valid_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3120\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sanitize_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3121\u001b[0m         \u001b[0mNDFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_ensure_valid_index\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m   3168\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_list_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3169\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3170\u001b[0;31m                 \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3171\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mValueError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3172\u001b[0m                 raise ValueError(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, dtype, name, copy, fastpath)\u001b[0m\n\u001b[1;32m    325\u001b[0m                     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 327\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msanitize_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_cast_failure\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    328\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSingleBlockManager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/construction.py\u001b[0m in \u001b[0;36msanitize_array\u001b[0;34m(data, index, dtype, copy, raise_cast_failure)\u001b[0m\n\u001b[1;32m    494\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0msubarr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 496\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Data must be 1-dimensional\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    497\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m             \u001b[0msubarr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray_tuplesafe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mException\u001b[0m: Data must be 1-dimensional"
          ]
        }
      ],
      "source": [
        "result['yhat'] = yhat\n",
        "result['actual'] = target_test\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "77ea9704-7bc9-4013-a399-6df194c06793",
      "metadata": {
        "id": "77ea9704-7bc9-4013-a399-6df194c06793"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "223a92c5-687e-49c5-947a-ad72e53ef2f1",
      "metadata": {
        "id": "223a92c5-687e-49c5-947a-ad72e53ef2f1"
      },
      "outputs": [],
      "source": [
        "result['class_pred'] = result['yhat'] > .5\n",
        "result['correct'] = result['actual'] == result['class_pred']\n",
        "result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e2f313b3-aa7f-4ca4-97de-c9c14365f9ca",
      "metadata": {
        "id": "e2f313b3-aa7f-4ca4-97de-c9c14365f9ca"
      },
      "outputs": [],
      "source": [
        "accuracy = result.correct.sum()/len(result.correct)\n",
        "print('Accuracy:' + str(accuracy))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c8075705-597e-4d0d-9a17-d381378f1ded",
      "metadata": {
        "id": "c8075705-597e-4d0d-9a17-d381378f1ded"
      },
      "source": [
        "### 3d"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3860ca03-2f03-417c-a5cd-de6c6d49fd21",
      "metadata": {
        "id": "3860ca03-2f03-417c-a5cd-de6c6d49fd21"
      },
      "outputs": [],
      "source": [
        "for x in range(32):\n",
        "    \n",
        "    test_file = f\"PARM{x}_TEST.tsv\"\n",
        "    train_file = f\"PARM{x}_TRAIN.tsv\"\n",
        "    \n",
        "    test_dataset = pd.read_csv(test_file, sep='\\t', header = None)\n",
        "    train_dataset = pd.read_csv(train_file, sep='\\t', header = None)\n",
        "    \n",
        "    column_names = ['f' + str(x) for x in train_dataset.columns]\n",
        "    column_names[0] = 'outcome'\n",
        "   \n",
        "\n",
        "    train_dataset.columns = column_names\n",
        "    test_dataset.columns = column_names\n",
        "    \n",
        "    train_dataset['outcome'] = train_dataset['outcome'].replace(-1, 0)\n",
        "    test_dataset['outcome'] = test_dataset['outcome'].replace(-1, 0)\n",
        "    \n",
        "    training_df.append(train_dataset)\n",
        "    test_df.append(test_dataset)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.11"
    },
    "colab": {
      "name": "SFA_transform.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}